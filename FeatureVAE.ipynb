{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYJiU3CCVXgD"
      },
      "source": [
        "# Feature VAE\n",
        "This notebook contains the code for generating the VAE responsible for compressing graph features (i.e., node and edge features) into a low dimension space to be sampled and to generate a new feature set to be passed to the aligner."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 15 s\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch_geometric.datasets import ZINC\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Make the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = ZINC(root = '', split='train') # valid, test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current device: NVIDIA GeForce GTX 1660 Ti with Max-Q Design\n"
          ]
        }
      ],
      "source": [
        "# Check which device we are currently using.\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.cuda.current_device()\n",
        "  print(\"Current device:\", torch.cuda.get_device_name(device))\n",
        "  \n",
        "else:\n",
        "  print(\"Using CPU\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print out a sample of the dataset.\n",
        "# dataset[0].to_namedtuple() # x, edge_index, edge_attr, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Converts a row of data from the pytorch geometric ZINC dataset into\n",
        "a matrix representation by stacking edges and padding. \n",
        "\n",
        "Args:\n",
        "    layer: a row of data from the pytorch geometric ZINC dataset. \n",
        "\n",
        "Returns:\n",
        "    A graph of the zinc dataset represented as a matrix.\n",
        "\"\"\"\n",
        "def convert_row(row):\n",
        "    x = row.x\n",
        "    edge_index = row.edge_index\n",
        "    edge_attr = row.edge_attr\n",
        "    edge_reprs = [set(), set(), set()]\n",
        "\n",
        "    # Unpack row and store result in edge_reprs.\n",
        "    for edge_idx, (edge_i, edge_j) in enumerate(zip(edge_index[0], edge_index[1])):\n",
        "        # Extract the attributes. \n",
        "        src_node_att = x[edge_i.item()].item()\n",
        "        dst_node_att = x[edge_j.item()].item()\n",
        "        edge_att = edge_attr[edge_idx].item()\n",
        "\n",
        "        # Append to edge_reprs.\n",
        "        edge_reprs[0].add(edge_att)\n",
        "        edge_reprs[1].add(src_node_att)\n",
        "        edge_reprs[2].add(dst_node_att)\n",
        "\n",
        "    # Convert the edge_repr sets to lists. \n",
        "    edge_reprs = [list(edge_repr) for edge_repr in edge_reprs]\n",
        "\n",
        "    # Add padding to make each list the same size.\n",
        "    maxlen = max([len(s) for s in edge_reprs])\n",
        "    for edge_repr in edge_reprs:\n",
        "        while len(edge_repr) < maxlen:\n",
        "            edge_repr.append(0)\n",
        "\n",
        "    # Convert edge_reprs into a tensor.\n",
        "    graph_repr = []\n",
        "    for e, v1, v2 in zip(edge_reprs[0], edge_reprs[1], edge_reprs[2]):\n",
        "        e_t = torch.tensor([e])\n",
        "        v1_t = torch.tensor([v1])\n",
        "        v2_t = torch.tensor([v2])\n",
        "        graph_repr.append(torch.cat([torch.nn.functional.one_hot(e_t, num_classes=4).squeeze(),\n",
        "                            torch.nn.functional.one_hot(v1_t, num_classes=28).squeeze(),\n",
        "                            torch.nn.functional.one_hot(v2_t, num_classes=28).squeeze()]))\n",
        "\n",
        "    return torch.stack(graph_repr)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print out what one converted row of data looks like.\n",
        "# convert_row(dataset[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5:20 mins\n",
        "# graph_lst = []\n",
        "# for row in dataset:\n",
        "#     graph_lst.append(convert_row(row))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 10 s\n",
        "# torch.save(graph_lst, \"data/graph_lst.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 10 s\n",
        "graph_lst = torch.load(\"data/graph_lst.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10\n"
          ]
        }
      ],
      "source": [
        "max_len = max(graph.shape[0] for graph in graph_lst)\n",
        "print(max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 22 s\n",
        "# Pad all the graphs in the dataset to make them the same size.\n",
        "padded_graph_lst = []\n",
        "for graph in graph_lst:\n",
        "    pad_len = max_len - graph.shape[0]\n",
        "    # print(pad_len)\n",
        "    pad_module = nn.ConstantPad2d((0, 0, 0, pad_len), value=0)\n",
        "    padded_graph = pad_module(graph)\n",
        "    padded_graph_lst.append(torch.flatten(padded_graph).float())\n",
        "    # print(padded_graph.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "600\n"
          ]
        }
      ],
      "source": [
        "input_dim = padded_graph_lst[0].shape[0]\n",
        "print(input_dim)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Convert padded_graph_lst into a VAEDataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import List, Optional, Sequence, Union\n",
        "from pytorch_lightning import LightningDataModule\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "\n",
        "# Add your custom dataset class here\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, padded_graph_lst):\n",
        "        self.padded_graph_lst = padded_graph_lst\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.padded_graph_lst)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.padded_graph_lst[idx]\n",
        "\n",
        "class VAEDataset(LightningDataModule):\n",
        "    \"\"\"\n",
        "    PyTorch Lightning data module \n",
        "\n",
        "    Args:\n",
        "        data_dir: root directory of your dataset.\n",
        "        train_batch_size: the batch size to use during training.\n",
        "        val_batch_size: the batch size to use during validation.\n",
        "        patch_size: the size of the crop to take from the original images.\n",
        "        num_workers: the number of parallel workers to create to load data\n",
        "            items (see PyTorch's Dataloader documentation for more details).\n",
        "        pin_memory: whether prepared items should be loaded into pinned memory\n",
        "            or not. This can improve performance on GPUs.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        data_path: str,\n",
        "        train_batch_size: int = 8,\n",
        "        val_batch_size: int = 8,\n",
        "        patch_size: Union[int, Sequence[int]] = (256, 256),\n",
        "        num_workers: int = 0,\n",
        "        pin_memory: bool = False,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.data_dir = data_path\n",
        "        self.train_batch_size = train_batch_size\n",
        "        self.val_batch_size = val_batch_size\n",
        "        self.patch_size = patch_size\n",
        "        self.num_workers = num_workers\n",
        "        self.pin_memory = pin_memory\n",
        "\n",
        "    def setup(self, stage: Optional[str] = None) -> None:\n",
        "        \n",
        "        self.train_dataset = MyDataset(padded_graph_lst)\n",
        "        \n",
        "        # Replace CelebA with your dataset\n",
        "        self.val_dataset = MyDataset(padded_graph_lst)\n",
        "#       ===============================================================\n",
        "        \n",
        "    def train_dataloader(self) -> DataLoader:\n",
        "        return DataLoader(\n",
        "            self.train_dataset,\n",
        "            batch_size=self.train_batch_size,\n",
        "            num_workers=self.num_workers,\n",
        "            shuffle=True,\n",
        "            pin_memory=self.pin_memory,\n",
        "        )\n",
        "\n",
        "    def val_dataloader(self) -> Union[DataLoader, List[DataLoader]]:\n",
        "        return DataLoader(\n",
        "            self.val_dataset,\n",
        "            batch_size=self.val_batch_size,\n",
        "            num_workers=self.num_workers,\n",
        "            shuffle=False,\n",
        "            pin_memory=self.pin_memory,\n",
        "        )\n",
        "    \n",
        "    def test_dataloader(self) -> Union[DataLoader, List[DataLoader]]:\n",
        "        return DataLoader(\n",
        "            self.val_dataset,\n",
        "            batch_size=144,\n",
        "            num_workers=self.num_workers,\n",
        "            shuffle=True,\n",
        "            pin_memory=self.pin_memory,\n",
        "        )\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "vae_data = VAEDataset(\"\")\n",
        "vae_data.setup()"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "# 3 Mins per epoch\n",
        "# Define optimizer\n",
        "learning_rate = 0.000001\n",
        "optimizer = torch.optim.Adam(MyVAE.parameters(), lr=learning_rate)\n",
        "\n",
        "print(gen_syn_graph())\n",
        "flag = False\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 20\n",
        "for epoch in tqdm(range(num_epochs), desc=\"epochs\"):\n",
        "    # print(\"epoch: \" + str(epoch))\n",
        "    for data in tqdm(vae_data.train_dataloader(), desc=\"batches\"):\n",
        "        # Get data\n",
        "        graph_vectors = data\n",
        "\n",
        "        # Forward pass\n",
        "        reconstructed_graphs, mu, logvar = MyVAE(graph_vectors)  # Extract latent variables\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = loss_function(reconstructed_graphs, graph_vectors, mu, logvar)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(MyVAE.parameters(), max_norm=0.001)  # Clip gradients with norm exceeding 1.0\n",
        "        optimizer.step()\n",
        "\n",
        "        gen_ten = reconstructed_graphs\n",
        "        # print(\"data: \" + str(data))\n",
        "        # print(\"gen: \" + str(gen_ten))\n",
        "        nan_mask = torch.isnan(gen_ten)\n",
        "        if nan_mask.any():\n",
        "            print(\"data: \" + str(data))\n",
        "            print(\"reconst: \" + str(reconstructed_graphs))\n",
        "            print(\"gen: \" + str(gen_ten))\n",
        "            print(\"FLOPPED!!\")\n",
        "            flag = True\n",
        "            break\n",
        "\n",
        "    if flag:\n",
        "        break\n",
        "\n",
        "    print(gen_syn_graph())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Make the VAE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "import torch.utils\n",
        "import torch.distributions\n",
        "import torchvision\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, latent_dims):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.linear1 = nn.Linear(input_dim, 512)\n",
        "        self.linear2 = nn.Linear(512, latent_dims)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        x = F.relu(self.linear1(x))\n",
        "        return self.linear2(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, input_dim, latent_dims):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.linear1 = nn.Linear(latent_dims, 512)\n",
        "        self.linear2 = nn.Linear(512, input_dim)\n",
        "\n",
        "    def forward(self, z):\n",
        "        z = F.relu(self.linear1(z))\n",
        "        z = torch.sigmoid(self.linear2(z))\n",
        "        return z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, input_dim, latent_dims):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        self.encoder = Encoder(input_dim, latent_dims)\n",
        "        self.decoder = Decoder(input_dim, latent_dims)\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.encoder(x)\n",
        "        return self.decoder(z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "def revert_onehot(tensor):\n",
        "    splits = torch.chunk(tensor.squeeze(), max_len)\n",
        "    row_lst = []\n",
        "    for split in splits:\n",
        "        subsplits = torch.split(split, [4, 28, 28])\n",
        "        # print(subsplits)\n",
        "        e = torch.argmax(subsplits[0])\n",
        "        v1 = torch.argmax(subsplits[1])\n",
        "        v2 = torch.argmax(subsplits[2])\n",
        "        row_lst.append(torch.tensor((e, v1, v2)))\n",
        "    return torch.stack(row_lst)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Train the VAE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(autoencoder, data, epochs=20):\n",
        "    opt = torch.optim.Adam(autoencoder.parameters())\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        for x in data:\n",
        "            x = x.to(device) # GPU\n",
        "            opt.zero_grad()\n",
        "            x_hat = autoencoder(x)\n",
        "            loss = ((x - x_hat)**2).sum()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "        latent_dim = 2\n",
        "        z = torch.randn(1, latent_dim).to(device)\n",
        "        print(revert_onehot(autoencoder.decoder(z)))\n",
        "    return autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0,  1, 18],\n",
            "        [ 3,  8,  5],\n",
            "        [ 0, 11, 11],\n",
            "        [ 0,  2,  2],\n",
            "        [ 2, 11, 20],\n",
            "        [ 1, 15, 20],\n",
            "        [ 1,  1, 20],\n",
            "        [ 1, 12, 27],\n",
            "        [ 0, 15,  3],\n",
            "        [ 0, 16, 12]])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/20 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  5%|â–Œ         | 1/20 [01:14<23:27, 74.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 1,  0,  0],\n",
            "        [ 2,  8,  8],\n",
            "        [ 0,  1,  1],\n",
            "        [ 0,  1,  1],\n",
            "        [ 2,  9,  9],\n",
            "        [ 1,  5, 10],\n",
            "        [ 1, 12, 12],\n",
            "        [ 3,  8, 16],\n",
            "        [ 0, 27,  8],\n",
            "        [ 1, 12,  2]])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|â–ˆ         | 2/20 [02:28<22:11, 74.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 1,  0,  0],\n",
            "        [ 2,  1,  1],\n",
            "        [ 0,  4,  4],\n",
            "        [ 0,  9,  9],\n",
            "        [ 3, 10, 10],\n",
            "        [ 2, 10, 10],\n",
            "        [ 0, 12, 12],\n",
            "        [ 0,  1, 25],\n",
            "        [ 2,  9, 19],\n",
            "        [ 1,  0, 18]])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 15%|â–ˆâ–Œ        | 3/20 [03:40<20:42, 73.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 1,  0,  0],\n",
            "        [ 0,  1,  1],\n",
            "        [ 0,  4,  4],\n",
            "        [ 0,  9,  9],\n",
            "        [ 3, 10, 10],\n",
            "        [ 3, 11, 11],\n",
            "        [ 0, 12, 12],\n",
            "        [ 0, 11,  1],\n",
            "        [ 0,  4, 15],\n",
            "        [ 0,  1,  3]])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|â–ˆâ–ˆ        | 4/20 [04:55<19:42, 73.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 1,  0,  0],\n",
            "        [ 2, 11, 11],\n",
            "        [ 0,  4,  4],\n",
            "        [ 0,  8,  8],\n",
            "        [ 3, 10, 10],\n",
            "        [ 3, 11, 11],\n",
            "        [ 2, 23, 17],\n",
            "        [ 2, 19,  7],\n",
            "        [ 1, 25, 16],\n",
            "        [ 0, 15,  3]])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|â–ˆâ–ˆâ–Œ       | 5/20 [06:08<18:25, 73.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 1,  0,  0],\n",
            "        [ 2, 11, 11],\n",
            "        [ 0,  4,  4],\n",
            "        [ 0,  6,  6],\n",
            "        [ 3, 10, 10],\n",
            "        [ 3, 18, 11],\n",
            "        [ 2, 23, 25],\n",
            "        [ 0, 19, 13],\n",
            "        [ 1, 25, 16],\n",
            "        [ 0, 15, 13]])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [07:24<17:22, 74.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 1,  0,  0],\n",
            "        [ 2,  2,  2],\n",
            "        [ 0,  4,  4],\n",
            "        [ 0,  6,  6],\n",
            "        [ 0, 10, 10],\n",
            "        [ 3,  7,  5],\n",
            "        [ 2,  2, 23],\n",
            "        [ 0, 19, 14],\n",
            "        [ 2, 27, 16],\n",
            "        [ 0, 20, 13]])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [08:45<16:36, 76.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 1,  0,  0],\n",
            "        [ 0,  8,  8],\n",
            "        [ 0,  4,  4],\n",
            "        [ 0,  1,  1],\n",
            "        [ 2,  9, 14],\n",
            "        [ 1,  5,  5],\n",
            "        [ 1,  1,  7],\n",
            "        [ 0,  3, 16],\n",
            "        [ 0, 27,  0],\n",
            "        [ 1,  1,  2]])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [10:07<15:39, 78.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 1,  0,  0],\n",
            "        [ 2,  2,  2],\n",
            "        [ 3,  5,  0],\n",
            "        [ 0, 15, 15],\n",
            "        [ 0, 14, 14],\n",
            "        [ 1,  5,  5],\n",
            "        [ 2, 14,  7],\n",
            "        [ 0, 19, 14],\n",
            "        [ 2, 27,  6],\n",
            "        [ 1, 20, 13]])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [11:28<14:30, 79.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 1,  0,  0],\n",
            "        [ 2, 11, 11],\n",
            "        [ 0,  4,  4],\n",
            "        [ 0,  6,  6],\n",
            "        [ 1, 14, 14],\n",
            "        [ 3,  5,  5],\n",
            "        [ 2, 14, 25],\n",
            "        [ 0, 19, 13],\n",
            "        [ 0, 25, 16],\n",
            "        [ 0, 15,  3]])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [12:48<13:14, 79.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 1,  0,  0],\n",
            "        [ 0,  1,  1],\n",
            "        [ 0,  4,  4],\n",
            "        [ 0,  9,  9],\n",
            "        [ 1, 10, 10],\n",
            "        [ 3, 11,  5],\n",
            "        [ 1, 14,  2],\n",
            "        [ 2, 26,  2],\n",
            "        [ 0, 25, 16],\n",
            "        [ 0,  1,  3]])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [14:09<11:59, 79.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 1,  0,  0],\n",
            "        [ 2,  1,  1],\n",
            "        [ 0,  4,  4],\n",
            "        [ 0,  9,  9],\n",
            "        [ 1, 15, 15],\n",
            "        [ 3, 12, 12],\n",
            "        [ 0, 12, 12],\n",
            "        [ 0, 17,  3],\n",
            "        [ 0,  7, 26],\n",
            "        [ 1,  1,  3]])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [15:30<10:41, 80.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 1,  0,  0],\n",
            "        [ 0,  1,  1],\n",
            "        [ 0,  4,  4],\n",
            "        [ 0, 10, 10],\n",
            "        [ 1, 14, 14],\n",
            "        [ 3,  5,  5],\n",
            "        [ 1, 14,  2],\n",
            "        [ 2, 26,  2],\n",
            "        [ 0, 25, 16],\n",
            "        [ 0, 14,  3]])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [16:50<09:22, 80.29s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 1,  0,  0],\n",
            "        [ 2, 11, 11],\n",
            "        [ 0,  4,  4],\n",
            "        [ 0, 15, 15],\n",
            "        [ 1, 14, 14],\n",
            "        [ 3,  5,  5],\n",
            "        [ 2, 14, 23],\n",
            "        [ 0, 19, 13],\n",
            "        [ 2, 27, 16],\n",
            "        [ 1, 20, 13]])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [18:09<07:58, 79.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 1,  0,  0],\n",
            "        [ 2,  2,  2],\n",
            "        [ 0,  4,  6],\n",
            "        [ 0, 15, 15],\n",
            "        [ 1, 14, 14],\n",
            "        [ 3,  5,  5],\n",
            "        [ 2, 14, 23],\n",
            "        [ 0, 19, 13],\n",
            "        [ 2, 27, 16],\n",
            "        [ 1, 20, 13]])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [19:27<06:36, 79.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 1,  0,  0],\n",
            "        [ 0, 11, 11],\n",
            "        [ 0,  6,  6],\n",
            "        [ 0, 15,  1],\n",
            "        [ 2, 14, 14],\n",
            "        [ 1,  5,  5],\n",
            "        [ 1,  5,  7],\n",
            "        [ 0,  3, 16],\n",
            "        [ 0, 27,  0],\n",
            "        [ 1, 25, 20]])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [20:45<05:15, 78.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 1,  0,  0],\n",
            "        [ 0, 11, 11],\n",
            "        [ 0,  4,  4],\n",
            "        [ 1,  1,  1],\n",
            "        [ 1, 14, 14],\n",
            "        [ 1,  5,  5],\n",
            "        [ 1,  5,  7],\n",
            "        [ 0,  3, 16],\n",
            "        [ 0, 27,  0],\n",
            "        [ 1, 25, 20]])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [22:07<03:59, 79.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 1,  0,  0],\n",
            "        [ 2, 11, 11],\n",
            "        [ 0,  4,  4],\n",
            "        [ 0, 15, 15],\n",
            "        [ 1, 14, 14],\n",
            "        [ 3,  5,  5],\n",
            "        [ 2, 14, 25],\n",
            "        [ 0, 19, 13],\n",
            "        [ 0, 25, 16],\n",
            "        [ 0, 20, 13]])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [23:34<02:43, 81.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 1,  0,  0],\n",
            "        [ 2,  1,  1],\n",
            "        [ 0,  4,  4],\n",
            "        [ 0,  6,  6],\n",
            "        [ 1, 15, 15],\n",
            "        [ 3, 11,  9],\n",
            "        [ 1,  8, 13],\n",
            "        [ 0,  8,  3],\n",
            "        [ 0, 25,  0],\n",
            "        [ 1,  1, 20]])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [24:53<01:20, 80.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 1,  0,  0],\n",
            "        [ 2,  2,  2],\n",
            "        [ 3,  6,  6],\n",
            "        [ 0, 15, 15],\n",
            "        [ 3, 14, 14],\n",
            "        [ 1,  5,  5],\n",
            "        [ 2, 14,  7],\n",
            "        [ 0, 19, 14],\n",
            "        [ 2, 27, 12],\n",
            "        [ 1, 20, 13]])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [26:11<00:00, 78.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 1,  0,  0],\n",
            "        [ 2, 10, 10],\n",
            "        [ 0, 15, 15],\n",
            "        [ 0, 16, 16],\n",
            "        [ 1, 16, 16],\n",
            "        [ 3, 11,  5],\n",
            "        [ 1, 20,  7],\n",
            "        [ 0,  8, 16],\n",
            "        [ 2, 21,  0],\n",
            "        [ 1, 20, 20]])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "latent_dims = 2\n",
        "autoencoder = Autoencoder(input_dim, latent_dims).to(device) # GPU\n",
        "z = torch.randn(1, latent_dims).to(device)\n",
        "print(revert_onehot(autoencoder.decoder(z)))\n",
        "autoencoder = train(autoencoder, vae_data.train_dataloader())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save(autoencoder, \"autoencoder.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observe the VAE Performance ðŸ“ˆ**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 1,  0,  0],\n",
            "        [ 2,  1,  1],\n",
            "        [ 0,  4,  4],\n",
            "        [ 0,  9,  9],\n",
            "        [ 1, 15, 15],\n",
            "        [ 3, 11,  5],\n",
            "        [ 3, 15,  2],\n",
            "        [ 0,  8,  3],\n",
            "        [ 0, 25, 22],\n",
            "        [ 1, 20, 20]])\n"
          ]
        }
      ],
      "source": [
        "# After training the VAE\n",
        "\n",
        "# Sample a random point in the latent space\n",
        "z = torch.randn(1, latent_dims).to(device)\n",
        "\n",
        "# Decode the sampled latent vector to get a new vector\n",
        "print(revert_onehot(autoencoder.decoder(z)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt; plt.rcParams['figure.dpi'] = 200\n",
        "\n",
        "def plot_latent(autoencoder, data, num_batches=100):\n",
        "    for i, (x, y) in enumerate(data):\n",
        "        z = autoencoder.encoder(x.to(device))\n",
        "        z = z.to('cpu').detach().numpy()\n",
        "        plt.scatter(z[:, 0], z[:, 1], c=y, cmap='tab10')\n",
        "        if i > num_batches:\n",
        "            plt.colorbar()\n",
        "            break"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
